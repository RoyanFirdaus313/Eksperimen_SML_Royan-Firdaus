# -*- coding: utf-8 -*-
"""Untitled19.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cMZd7FKmOAcsL3Rb9Gd3BnN_nr7WnWJb

#Kriteria 1(Skilled)

automatisasi
"""

import pandas as pd
from sklearn.preprocessing import StandardScaler

def load_data(path):
    try:
        df = pd.read_csv(path)
    except pd.errors.ParserError:
        df = pd.read_csv(path, sep=';')
    return df


def preprocess(df):
    # 1. Drop missing values
    df_cleaned = df.dropna()

    # 2. Drop duplicates
    df_cleaned = df_cleaned.drop_duplicates()

    # Identify numerical & categorical columns
    num_cols = df_cleaned.select_dtypes(include=['int64', 'float64']).columns
    cat_cols = df_cleaned.select_dtypes(include=['object']).columns

    # 3. Scaling numerical features
    scaler = StandardScaler()
    df_cleaned[num_cols] = scaler.fit_transform(df_cleaned[num_cols])

    # 4. One-hot encoding categorical features
    df_cleaned = pd.get_dummies(df_cleaned, columns=cat_cols, drop_first=True)

    # 5. Handle outliers using IQR capping
    for col in num_cols:
        Q1 = df_cleaned[col].quantile(0.25)
        Q3 = df_cleaned[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        df_cleaned[col] = df_cleaned[col].clip(lower, upper)

    return df_cleaned


if __name__ == "__main__":
    # Path input & output
    input_path = "train_df_raw/train_df.csv"
    output_path = "preprocessing/cleaned_df.csv"

    df = load_data(input_path)
    df_cleaned = preprocess(df)

    df_cleaned.to_csv(output_path, index=False)
    print("âœ… Preprocessing selesai. Dataset tersimpan.")